{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input\n",
    "from collections import Counter\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var60</th>\n",
       "      <th>var61</th>\n",
       "      <th>var62</th>\n",
       "      <th>var63</th>\n",
       "      <th>var64</th>\n",
       "      <th>var65</th>\n",
       "      <th>var66</th>\n",
       "      <th>var67</th>\n",
       "      <th>var68</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>2853</td>\n",
       "      <td>29442</td>\n",
       "      <td>1386</td>\n",
       "      <td>2435</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311441</td>\n",
       "      <td>0.142303</td>\n",
       "      <td>0.056146</td>\n",
       "      <td>0.632694</td>\n",
       "      <td>0.024054</td>\n",
       "      <td>0.253356</td>\n",
       "      <td>0.00603</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>1986</td>\n",
       "      <td>13684</td>\n",
       "      <td>7189</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.070991</td>\n",
       "      <td>0.773966</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00000</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.106618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1019</td>\n",
       "      <td>10232</td>\n",
       "      <td>678</td>\n",
       "      <td>791</td>\n",
       "      <td>16</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.200814</td>\n",
       "      <td>0.051046</td>\n",
       "      <td>0.980827</td>\n",
       "      <td>0.018536</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00000</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.242647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>1751</td>\n",
       "      <td>2689</td>\n",
       "      <td>8235</td>\n",
       "      <td>1042</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.352379</td>\n",
       "      <td>0.044301</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.363370</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>2262</td>\n",
       "      <td>29428</td>\n",
       "      <td>6031</td>\n",
       "      <td>304</td>\n",
       "      <td>16</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021226</td>\n",
       "      <td>0.226161</td>\n",
       "      <td>0.059125</td>\n",
       "      <td>0.906155</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00000</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  var1  var2  var3   var4  var5  var6  var7  var8  var9  ...       var60  \\\n",
       "0   1    18    19  2853  29442  1386  2435    35  -999     3  ...    0.311441   \n",
       "1   8     4   110  1986  13684  7189  -999  -999    17     3  ... -999.000000   \n",
       "2  30     0    39  1019  10232   678   791    16  -999     3  ... -999.000000   \n",
       "3  43    20    39  1751   2689  8235  1042    13    10     1  ... -999.000000   \n",
       "4  46     7    44  2262  29428  6031   304    16  -999     3  ...    0.021226   \n",
       "\n",
       "        var61     var62     var63     var64       var65      var66     var67  \\\n",
       "0    0.142303  0.056146  0.632694  0.024054    0.253356    0.00603  0.132353   \n",
       "1 -999.000000  0.070991  0.773966  0.019315 -999.000000 -999.00000  0.147059   \n",
       "2    0.200814  0.051046  0.980827  0.018536 -999.000000 -999.00000  0.382353   \n",
       "3    0.352379  0.044301  0.951564  0.023684    0.363370    0.00201  0.147059   \n",
       "4    0.226161  0.059125  0.906155  0.020733 -999.000000 -999.00000  0.455882   \n",
       "\n",
       "      var68  y  \n",
       "0  0.139706  1  \n",
       "1  0.106618  0  \n",
       "2  0.242647  0  \n",
       "3  0.132353  0  \n",
       "4  0.132353  1  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variavel cod</th>\n",
       "      <th>Variavel tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>var1</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>var2</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>var3</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var4</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variavel cod        Variavel tipo\n",
       "0           id  Qualitativo nominal\n",
       "1         var1  Qualitativo nominal\n",
       "2         var2  Qualitativo nominal\n",
       "3         var3  Qualitativo nominal\n",
       "4         var4  Qualitativo nominal"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.read_csv(\"../data/metadata.csv\")\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qualitativo nominal      36\n",
       "Quantitativo discreto    18\n",
       "Quantitativo continua    12\n",
       "Qualitativo ordinal       4\n",
       "Name: Variavel tipo, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta[\"Variavel tipo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14123, 70)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var51        2\n",
       "var27        2\n",
       "var49        2\n",
       "var50        2\n",
       "var31        2\n",
       "         ...  \n",
       "var62    11613\n",
       "var11    12384\n",
       "var4     13094\n",
       "var55    14003\n",
       "id       14123\n",
       "Length: 69, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nunique = df_train.drop(\"y\", axis=1).apply(lambda x: len(np.unique(x)), axis=0).sort_values()\n",
    "nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train[\"id\"].value_counts() > 1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 35306)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"id\"].min(), df_train[\"id\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = df_meta[df_meta[\"Variavel tipo\"] == \"Qualitativo nominal\"][\"Variavel cod\"]\n",
    "# for col in df_train[df_meta].columns:\n",
    "#     n = df_train[df_train[col].isin(df_train[\"id\"].values)].shape[0]\n",
    "#     print(col, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Database (no features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"y\"]\n",
    "df_train.drop(\"y\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1, F1: 0.6285119667013527\n",
      "fold 2, F1: 0.5895196506550219\n",
      "fold 3, F1: 0.5911542610571736\n",
      "fold 4, F1: 0.5881081081081081\n",
      "fold 5, F1: 0.574863387978142\n",
      "CV F1: 0.594745908699397\n"
     ]
    }
   ],
   "source": [
    "train_preds = y.to_frame(\"y\")\n",
    "train_preds[\"preds\"] = 0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_train, y)):\n",
    "    x_train, x_test = df_train.loc[train_index], df_train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        random_state=0,\n",
    "        n_jobs=5\n",
    "    )\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(x_test)\n",
    "    train_preds.loc[test_index, \"preds\"] = y_pred\n",
    "    \n",
    "    score = f1_score(y_test, y_pred)    \n",
    "    print(f\"fold {fold+1}, F1: {score}\")\n",
    "    \n",
    "score = f1_score(train_preds[\"y\"], train_preds[\"preds\"])\n",
    "print(f\"CV F1: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.901491\tvalid_0's binary_logloss: 0.2936\n",
      "Early stopping, best iteration is:\n",
      "[659]\tvalid_0's auc: 0.9016\tvalid_0's binary_logloss: 0.295855\n",
      "fold 1, F1: 0.6811023622047244\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.889659\tvalid_0's binary_logloss: 0.307208\n",
      "Early stopping, best iteration is:\n",
      "[625]\tvalid_0's auc: 0.890913\tvalid_0's binary_logloss: 0.307425\n",
      "fold 2, F1: 0.6462167689161554\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.883871\tvalid_0's binary_logloss: 0.315589\n",
      "Early stopping, best iteration is:\n",
      "[1002]\tvalid_0's auc: 0.883909\tvalid_0's binary_logloss: 0.315565\n",
      "fold 3, F1: 0.6292585170340682\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.891767\tvalid_0's binary_logloss: 0.308735\n",
      "Early stopping, best iteration is:\n",
      "[980]\tvalid_0's auc: 0.892185\tvalid_0's binary_logloss: 0.30846\n",
      "fold 4, F1: 0.6363636363636365\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.877192\tvalid_0's binary_logloss: 0.321564\n",
      "Early stopping, best iteration is:\n",
      "[838]\tvalid_0's auc: 0.876391\tvalid_0's binary_logloss: 0.321349\n",
      "fold 5, F1: 0.6183673469387755\n",
      "CV F1: 0.64251012145749\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_preds = y.to_frame(\"y\")\n",
    "train_preds[\"preds\"] = 0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_train, y)):\n",
    "    x_train, x_test = df_train.loc[train_index], df_train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=5000,\n",
    "        random_state=42,\n",
    "        objective=\"binary\",\n",
    "        subsample=0.8,\n",
    "        subsample_freq=10,\n",
    "        colsample_bytree=0.8,\n",
    "        max_depth=5\n",
    "    )\n",
    "    clf.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_test, y_test)],\n",
    "        eval_metric=\"auc\",\n",
    "        early_stopping_rounds=500,\n",
    "        verbose=1000\n",
    "    )\n",
    "    \n",
    "    y_pred = clf.predict(x_test, num_iteration=clf.best_iteration_)\n",
    "    train_preds.loc[test_index, \"preds\"] = y_pred\n",
    "    \n",
    "    score = f1_score(y_test, y_pred)    \n",
    "    print(f\"fold {fold+1}, F1: {score}\")\n",
    "    \n",
    "score = f1_score(train_preds[\"y\"], train_preds[\"preds\"])\n",
    "print(f\"CV F1: {score}\")\n",
    "\n",
    "\n",
    "# CV F1: 0.594745908699397 Raw data RF\n",
    "# CV F1: 0.6434923201293452 Raw Data LGB: No params\n",
    "# CV F1: 0.64251012145749 Raw Data LGB: Some params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11298 samples, validate on 2825 samples\n",
      "Epoch 1/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.4959 - auc: 0.7085 - val_loss: 0.4073 - val_auc: 0.7473\n",
      "Epoch 2/10\n",
      "11298/11298 [==============================] - 17s 1ms/step - loss: 0.4195 - auc: 0.7564 - val_loss: 0.3998 - val_auc: 0.7619\n",
      "Epoch 3/10\n",
      "11298/11298 [==============================] - 17s 2ms/step - loss: 0.4062 - auc: 0.7654 - val_loss: 0.4250 - val_auc: 0.7718\n",
      "Epoch 4/10\n",
      "11298/11298 [==============================] - 17s 2ms/step - loss: 0.3945 - auc: 0.7754 - val_loss: 0.3757 - val_auc: 0.7808\n",
      "Epoch 5/10\n",
      "11298/11298 [==============================] - 17s 2ms/step - loss: 0.3924 - auc: 0.7835 - val_loss: 0.3793 - val_auc: 0.7870\n",
      "Epoch 6/10\n",
      "11298/11298 [==============================] - 17s 2ms/step - loss: 0.3924 - auc: 0.7887 - val_loss: 0.3933 - val_auc: 0.7905\n",
      "Epoch 7/10\n",
      "11298/11298 [==============================] - 17s 2ms/step - loss: 0.3836 - auc: 0.7918 - val_loss: 0.3966 - val_auc: 0.7942\n",
      "Epoch 8/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.3808 - auc: 0.7957 - val_loss: 0.3773 - val_auc: 0.7974\n",
      "Epoch 9/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.3774 - auc: 0.7988 - val_loss: 0.4175 - val_auc: 0.8003\n",
      "Epoch 10/10\n",
      "11298/11298 [==============================] - 19s 2ms/step - loss: 0.3766 - auc: 0.8010 - val_loss: 0.3661 - val_auc: 0.8028\n",
      "fold:1, f1_score = 0.5832492431886983\n",
      "Train on 11298 samples, validate on 2825 samples\n",
      "Epoch 1/10\n",
      "11298/11298 [==============================] - 20s 2ms/step - loss: 0.4913 - auc: 0.7151 - val_loss: 0.4150 - val_auc: 0.7415\n",
      "Epoch 2/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.4180 - auc: 0.7491 - val_loss: 0.4035 - val_auc: 0.7599\n",
      "Epoch 3/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.4025 - auc: 0.7656 - val_loss: 0.4010 - val_auc: 0.7728\n",
      "Epoch 4/10\n",
      "11298/11298 [==============================] - 19s 2ms/step - loss: 0.4036 - auc: 0.7755 - val_loss: 0.3849 - val_auc: 0.7800\n",
      "Epoch 5/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.3936 - auc: 0.7827 - val_loss: 0.4069 - val_auc: 0.7854\n",
      "Epoch 6/10\n",
      "11298/11298 [==============================] - 19s 2ms/step - loss: 0.3870 - auc: 0.7872 - val_loss: 0.3815 - val_auc: 0.7897\n",
      "Epoch 7/10\n",
      "11298/11298 [==============================] - 19s 2ms/step - loss: 0.3829 - auc: 0.7917 - val_loss: 0.3854 - val_auc: 0.7940\n",
      "Epoch 8/10\n",
      "11298/11298 [==============================] - 19s 2ms/step - loss: 0.3742 - auc: 0.7959 - val_loss: 0.3642 - val_auc: 0.7985\n",
      "Epoch 9/10\n",
      "11298/11298 [==============================] - 19s 2ms/step - loss: 0.3674 - auc: 0.8007 - val_loss: 0.3915 - val_auc: 0.8025\n",
      "Epoch 10/10\n",
      "11298/11298 [==============================] - 20s 2ms/step - loss: 0.3632 - auc: 0.8041 - val_loss: 0.3693 - val_auc: 0.8062\n",
      "fold:2, f1_score = 0.534446764091858\n",
      "Train on 11298 samples, validate on 2825 samples\n",
      "Epoch 1/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.5030 - auc: 0.7121 - val_loss: 0.4362 - val_auc: 0.7308\n",
      "Epoch 2/10\n",
      " 5664/11298 [==============>...............] - ETA: 8s - loss: 0.4232 - auc: 0.7379"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-beb207f6195e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mx_test_scl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_scl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_scl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;31m#     clf.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros(df_train.shape[0])\n",
    "# sub_preds = np.zeros(df_test_agg.shape[0])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_train, y)):\n",
    "    x_train, x_test = df_train.loc[train_index], df_train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(2000, input_dim=x_train.shape[1], activation='relu'))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Dropout(0.3))\n",
    "    \n",
    "    clf.add(Dense(1000, activation='sigmoid'))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Dropout(0.3))\n",
    "    \n",
    "    clf.add(Dense(500, activation='sigmoid'))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Dropout(0.2))\n",
    "    \n",
    "    clf.add(Dense(100, activation='sigmoid'))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Dropout(0.2))\n",
    "    clf.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC()])\n",
    "    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=10,\n",
    "                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n",
    "                                      patience=3, min_lr=1e-6, mode='max', verbose=1)\n",
    "    scalar = MinMaxScaler()\n",
    "    scalar.fit(x_train)\n",
    "    x_train_scl = scalar.transform(x_train)\n",
    "    x_test_scl = scalar.transform(x_test)\n",
    "\n",
    "    clf.fit(x_train_scl, y_train, validation_data=(x_test_scl, y_test), callbacks=[es, rlr], epochs=10, batch_size=32)\n",
    "#     clf.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)\n",
    "    \n",
    "    val_preds = clf.predict_classes(x_test_scl)\n",
    "    score = f1_score(y_test, val_preds)\n",
    "    \n",
    "    print(f\"fold:{fold + 1}, f1_score = {score}\")\n",
    "    oof_preds[test_index] = val_preds.ravel()\n",
    "    \n",
    "    K.clear_session()\n",
    "    gc.collect()    \n",
    "    \n",
    "print('Full rmse score %.6f' % rmse(y, oof_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies with qualitative ordinal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before dummies:  (14123, 69)\n",
      "shape after dummies:  (14123, 144)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape before dummies: \", df_train.shape)\n",
    "cols = df_meta[df_meta[\"Variavel tipo\"] == \"Qualitativo ordinal\"][\"Variavel cod\"].values[1:]\n",
    "for col in cols:\n",
    "    df_dummies = pd.get_dummies(df_train[col])\n",
    "    df_dummies.columns = [f\"{col}_{suffix}\" for suffix in df_dummies.columns]\n",
    "    df_train = df_train.merge(df_dummies, how=\"left\", left_index=True, right_index=True)\n",
    "print(\"shape after dummies: \", df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.901652\tvalid_0's binary_logloss: 0.293686\n",
      "Early stopping, best iteration is:\n",
      "[1010]\tvalid_0's auc: 0.901829\tvalid_0's binary_logloss: 0.293532\n",
      "fold 1, F1: 0.6828322017458779\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.888988\tvalid_0's binary_logloss: 0.307288\n",
      "Early stopping, best iteration is:\n",
      "[624]\tvalid_0's auc: 0.890273\tvalid_0's binary_logloss: 0.307261\n",
      "fold 2, F1: 0.6489795918367347\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.884172\tvalid_0's binary_logloss: 0.315835\n",
      "[2000]\tvalid_0's auc: 0.885108\tvalid_0's binary_logloss: 0.315801\n",
      "Early stopping, best iteration is:\n",
      "[1810]\tvalid_0's auc: 0.885733\tvalid_0's binary_logloss: 0.315261\n",
      "fold 3, F1: 0.6379137412236711\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.891745\tvalid_0's binary_logloss: 0.310146\n",
      "Early stopping, best iteration is:\n",
      "[978]\tvalid_0's auc: 0.892062\tvalid_0's binary_logloss: 0.30987\n",
      "fold 4, F1: 0.6272066458982346\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.874781\tvalid_0's binary_logloss: 0.322854\n",
      "Early stopping, best iteration is:\n",
      "[820]\tvalid_0's auc: 0.874665\tvalid_0's binary_logloss: 0.32227\n",
      "fold 5, F1: 0.6210418794688457\n",
      "CV F1: 0.644040404040404\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_preds = y.to_frame(\"y\")\n",
    "train_preds[\"preds\"] = 0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_train, y)):\n",
    "    x_train, x_test = df_train.loc[train_index], df_train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=5000,\n",
    "        random_state=42,\n",
    "        objective=\"binary\",\n",
    "        subsample=0.8,\n",
    "        subsample_freq=10,\n",
    "        colsample_bytree=0.8,\n",
    "        max_depth=5\n",
    "    )\n",
    "    clf.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_test, y_test)],\n",
    "        eval_metric=\"auc\",\n",
    "        early_stopping_rounds=500,\n",
    "        verbose=1000\n",
    "    )\n",
    "    \n",
    "    y_pred = clf.predict(x_test, num_iteration=clf.best_iteration_)\n",
    "    train_preds.loc[test_index, \"preds\"] = y_pred\n",
    "    \n",
    "    score = f1_score(y_test, y_pred)    \n",
    "    print(f\"fold {fold+1}, F1: {score}\")\n",
    "    \n",
    "score = f1_score(train_preds[\"y\"], train_preds[\"preds\"])\n",
    "print(f\"CV F1: {score}\")\n",
    "\n",
    "# CV F1: 0.594745908699397 Raw data RF\n",
    "# CV F1: 0.6434923201293452 Raw Data LGB: No params\n",
    "# CV F1: 0.64251012145749 Raw Data LGB: Some params\n",
    "# CV F1: 0.644040404040404 Dummies on Qual. Ord: some params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11298 samples, validate on 2825 samples\n",
      "Epoch 1/10\n",
      "11298/11298 [==============================] - 16s 1ms/step - loss: 0.5095 - auc: 0.7040 - val_loss: 0.4155 - val_auc: 0.7298\n",
      "Epoch 2/10\n",
      "11298/11298 [==============================] - 16s 1ms/step - loss: 0.4244 - auc: 0.7412 - val_loss: 0.4046 - val_auc: 0.7535\n",
      "Epoch 3/10\n",
      "11298/11298 [==============================] - 15s 1ms/step - loss: 0.4068 - auc: 0.7597 - val_loss: 0.3927 - val_auc: 0.7677\n",
      "Epoch 4/10\n",
      "11298/11298 [==============================] - 16s 1ms/step - loss: 0.3971 - auc: 0.7719 - val_loss: 0.3908 - val_auc: 0.7772\n",
      "Epoch 5/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.3886 - auc: 0.7810 - val_loss: 0.3951 - val_auc: 0.7842\n",
      "Epoch 6/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.3855 - auc: 0.7862 - val_loss: 0.3850 - val_auc: 0.7892\n",
      "Epoch 7/10\n",
      "11298/11298 [==============================] - 20s 2ms/step - loss: 0.3841 - auc: 0.7910 - val_loss: 0.4100 - val_auc: 0.7928\n",
      "Epoch 8/10\n",
      "11298/11298 [==============================] - 17s 1ms/step - loss: 0.3781 - auc: 0.7942 - val_loss: 0.4492 - val_auc: 0.7960\n",
      "Epoch 9/10\n",
      "11298/11298 [==============================] - 17s 1ms/step - loss: 0.3724 - auc: 0.7969 - val_loss: 0.3876 - val_auc: 0.7990\n",
      "Epoch 10/10\n",
      "11298/11298 [==============================] - 17s 1ms/step - loss: 0.3695 - auc: 0.8005 - val_loss: 0.3858 - val_auc: 0.8022\n",
      "fold:1, f1_score = 0.5078651685393258\n",
      "Train on 11298 samples, validate on 2825 samples\n",
      "Epoch 1/10\n",
      "11298/11298 [==============================] - 18s 2ms/step - loss: 0.5056 - auc: 0.7025 - val_loss: 0.4063 - val_auc: 0.7349\n",
      "Epoch 2/10\n",
      "  160/11298 [..............................] - ETA: 16s - loss: 0.4723 - auc: 0.7384"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-beb207f6195e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mx_test_scl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_scl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_scl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;31m#     clf.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros(df_train.shape[0])\n",
    "# sub_preds = np.zeros(df_test_agg.shape[0])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_train, y)):\n",
    "    x_train, x_test = df_train.loc[train_index], df_train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(2000, input_dim=x_train.shape[1], activation='relu'))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Dropout(0.3))\n",
    "    \n",
    "    clf.add(Dense(1000, activation='sigmoid'))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Dropout(0.3))\n",
    "    \n",
    "    clf.add(Dense(500, activation='sigmoid'))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Dropout(0.2))\n",
    "    \n",
    "    clf.add(Dense(100, activation='sigmoid'))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Dropout(0.2))\n",
    "    clf.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC()])\n",
    "    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=10,\n",
    "                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n",
    "                                      patience=3, min_lr=1e-6, mode='max', verbose=1)\n",
    "    scalar = MinMaxScaler()\n",
    "    scalar.fit(x_train)\n",
    "    x_train_scl = scalar.transform(x_train)\n",
    "    x_test_scl = scalar.transform(x_test)\n",
    "\n",
    "    clf.fit(x_train_scl, y_train, validation_data=(x_test_scl, y_test), callbacks=[es, rlr], epochs=10, batch_size=32)\n",
    "#     clf.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)\n",
    "    \n",
    "    val_preds = clf.predict_classes(x_test_scl)\n",
    "    score = f1_score(y_test, val_preds)\n",
    "    \n",
    "    print(f\"fold:{fold + 1}, f1_score = {score}\")\n",
    "    oof_preds[test_index] = val_preds.ravel()\n",
    "    \n",
    "    K.clear_session()\n",
    "    gc.collect()    \n",
    "    \n",
    "print('Full rmse score %.6f' % rmse(y, oof_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies with qualitative nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before dummies:  (14123, 144)\n",
      "shape after dummies:  (14123, 46953)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape before dummies: \", df_train.shape)\n",
    "cols = df_meta[df_meta[\"Variavel tipo\"] == \"Qualitativo nominal\"][\"Variavel cod\"].values[1:]\n",
    "for col in cols:\n",
    "    df_dummies = pd.get_dummies(df_train[col])\n",
    "    df_dummies.columns = [f\"{col}_{suffix}\" for suffix in df_dummies.columns]\n",
    "    df_train = df_train.merge(df_dummies, how=\"left\", left_index=True, right_index=True)\n",
    "print(\"shape after dummies: \", df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.901045\tvalid_0's binary_logloss: 0.294575\n",
      "Early stopping, best iteration is:\n",
      "[736]\tvalid_0's auc: 0.90195\tvalid_0's binary_logloss: 0.295417\n",
      "fold 1, F1: 0.6828793774319066\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[475]\tvalid_0's auc: 0.88947\tvalid_0's binary_logloss: 0.309359\n",
      "fold 2, F1: 0.6475409836065573\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.88057\tvalid_0's binary_logloss: 0.318624\n",
      "Early stopping, best iteration is:\n",
      "[1385]\tvalid_0's auc: 0.881764\tvalid_0's binary_logloss: 0.317878\n",
      "fold 3, F1: 0.634\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.892076\tvalid_0's binary_logloss: 0.308138\n",
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's auc: 0.892893\tvalid_0's binary_logloss: 0.307204\n",
      "fold 4, F1: 0.6495901639344263\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's auc: 0.874484\tvalid_0's binary_logloss: 0.323996\n",
      "Early stopping, best iteration is:\n",
      "[832]\tvalid_0's auc: 0.874213\tvalid_0's binary_logloss: 0.323829\n",
      "fold 5, F1: 0.6153846153846153\n",
      "CV F1: 0.6462159434914228\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_preds = y.to_frame(\"y\")\n",
    "train_preds[\"preds\"] = 0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_train, y)):\n",
    "    x_train, x_test = df_train.loc[train_index], df_train.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=5000,\n",
    "        random_state=42,\n",
    "        objective=\"binary\",\n",
    "        subsample=0.8,\n",
    "        subsample_freq=10,\n",
    "        colsample_bytree=0.8,\n",
    "        max_depth=5\n",
    "    )\n",
    "    clf.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_test, y_test)],\n",
    "        eval_metric=\"auc\",\n",
    "        early_stopping_rounds=500,\n",
    "        verbose=1000\n",
    "    )\n",
    "    \n",
    "    y_pred = clf.predict(x_test, num_iteration=clf.best_iteration_)\n",
    "    train_preds.loc[test_index, \"preds\"] = y_pred\n",
    "    \n",
    "    score = f1_score(y_test, y_pred)    \n",
    "    print(f\"fold {fold+1}, F1: {score}\")\n",
    "    \n",
    "score = f1_score(train_preds[\"y\"], train_preds[\"preds\"])\n",
    "print(f\"CV F1: {score}\")\n",
    "\n",
    "# CV F1: 0.594745908699397 Raw data RF\n",
    "# CV F1: 0.6434923201293452 Raw Data LGB: No params\n",
    "# CV F1: 0.64251012145749 Raw Data LGB: Some params\n",
    "# CV F1: 0.644040404040404 Dummies on Qual. Ord: some params\n",
    "# CV F1: 0.6462159434914228 Dummies on Qual.Ord and Qual.Nom.: some params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var41_0</th>\n",
       "      <th>var41_1</th>\n",
       "      <th>var41_2</th>\n",
       "      <th>var41_3</th>\n",
       "      <th>var41_4</th>\n",
       "      <th>var41_5</th>\n",
       "      <th>var41_6</th>\n",
       "      <th>var41_7</th>\n",
       "      <th>var41_8</th>\n",
       "      <th>var41_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>2853</td>\n",
       "      <td>29442</td>\n",
       "      <td>1386</td>\n",
       "      <td>2435</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>1986</td>\n",
       "      <td>13684</td>\n",
       "      <td>7189</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1019</td>\n",
       "      <td>10232</td>\n",
       "      <td>678</td>\n",
       "      <td>791</td>\n",
       "      <td>16</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>1751</td>\n",
       "      <td>2689</td>\n",
       "      <td>8235</td>\n",
       "      <td>1042</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>2262</td>\n",
       "      <td>29428</td>\n",
       "      <td>6031</td>\n",
       "      <td>304</td>\n",
       "      <td>16</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46953 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  var1  var2  var3   var4  var5  var6  var7  var8  var9  ...  var41_0  \\\n",
       "0   1    18    19  2853  29442  1386  2435    35  -999     3  ...        0   \n",
       "1   8     4   110  1986  13684  7189  -999  -999    17     3  ...        0   \n",
       "2  30     0    39  1019  10232   678   791    16  -999     3  ...        0   \n",
       "3  43    20    39  1751   2689  8235  1042    13    10     1  ...        0   \n",
       "4  46     7    44  2262  29428  6031   304    16  -999     3  ...        0   \n",
       "\n",
       "   var41_1  var41_2  var41_3  var41_4  var41_5  var41_6  var41_7  var41_8  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        0        1        0        0        0        0        0   \n",
       "3        0        0        1        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   var41_9  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 46953 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_meta[\"Variavel cod\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_sum = df_train[cols].apply(lambda x: sum(x == -999), axis=1)\n",
    "na_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fddf72d5f60>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(y, na_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14118</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14119</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14120</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14121</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14122</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14123 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_na\n",
       "0         1\n",
       "1         2\n",
       "2         1\n",
       "3         0\n",
       "4         1\n",
       "...     ...\n",
       "14118     2\n",
       "14119    11\n",
       "14120     0\n",
       "14121     0\n",
       "14122     0\n",
       "\n",
       "[14123 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_sum.to_frame(\"n_na\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
