{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, auc, precision_score, recall_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "SEED = 1996\n",
    "FOLDS = 5\n",
    "TARGET = \"y\"\n",
    "VERSION = \"lgbm-v5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var60</th>\n",
       "      <th>var61</th>\n",
       "      <th>var62</th>\n",
       "      <th>var63</th>\n",
       "      <th>var64</th>\n",
       "      <th>var65</th>\n",
       "      <th>var66</th>\n",
       "      <th>var67</th>\n",
       "      <th>var68</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>2853</td>\n",
       "      <td>29442</td>\n",
       "      <td>1386</td>\n",
       "      <td>2435</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311441</td>\n",
       "      <td>0.142303</td>\n",
       "      <td>0.056146</td>\n",
       "      <td>0.632694</td>\n",
       "      <td>0.024054</td>\n",
       "      <td>0.253356</td>\n",
       "      <td>0.00603</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>1986</td>\n",
       "      <td>13684</td>\n",
       "      <td>7189</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.070991</td>\n",
       "      <td>0.773966</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00000</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.106618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1019</td>\n",
       "      <td>10232</td>\n",
       "      <td>678</td>\n",
       "      <td>791</td>\n",
       "      <td>16</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.200814</td>\n",
       "      <td>0.051046</td>\n",
       "      <td>0.980827</td>\n",
       "      <td>0.018536</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00000</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.242647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>1751</td>\n",
       "      <td>2689</td>\n",
       "      <td>8235</td>\n",
       "      <td>1042</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.352379</td>\n",
       "      <td>0.044301</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.363370</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>2262</td>\n",
       "      <td>29428</td>\n",
       "      <td>6031</td>\n",
       "      <td>304</td>\n",
       "      <td>16</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021226</td>\n",
       "      <td>0.226161</td>\n",
       "      <td>0.059125</td>\n",
       "      <td>0.906155</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00000</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  var1  var2  var3   var4  var5  var6  var7  var8  var9  ...       var60  \\\n",
       "0   1    18    19  2853  29442  1386  2435    35  -999     3  ...    0.311441   \n",
       "1   8     4   110  1986  13684  7189  -999  -999    17     3  ... -999.000000   \n",
       "2  30     0    39  1019  10232   678   791    16  -999     3  ... -999.000000   \n",
       "3  43    20    39  1751   2689  8235  1042    13    10     1  ... -999.000000   \n",
       "4  46     7    44  2262  29428  6031   304    16  -999     3  ...    0.021226   \n",
       "\n",
       "        var61     var62     var63     var64       var65      var66     var67  \\\n",
       "0    0.142303  0.056146  0.632694  0.024054    0.253356    0.00603  0.132353   \n",
       "1 -999.000000  0.070991  0.773966  0.019315 -999.000000 -999.00000  0.147059   \n",
       "2    0.200814  0.051046  0.980827  0.018536 -999.000000 -999.00000  0.382353   \n",
       "3    0.352379  0.044301  0.951564  0.023684    0.363370    0.00201  0.147059   \n",
       "4    0.226161  0.059125  0.906155  0.020733 -999.000000 -999.00000  0.455882   \n",
       "\n",
       "      var68  y  \n",
       "0  0.139706  1  \n",
       "1  0.106618  0  \n",
       "2  0.242647  0  \n",
       "3  0.132353  0  \n",
       "4  0.132353  1  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var59</th>\n",
       "      <th>var60</th>\n",
       "      <th>var61</th>\n",
       "      <th>var62</th>\n",
       "      <th>var63</th>\n",
       "      <th>var64</th>\n",
       "      <th>var65</th>\n",
       "      <th>var66</th>\n",
       "      <th>var67</th>\n",
       "      <th>var68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>28956</td>\n",
       "      <td>743</td>\n",
       "      <td>1289</td>\n",
       "      <td>27</td>\n",
       "      <td>-999</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201839</td>\n",
       "      <td>0.353965</td>\n",
       "      <td>0.166641</td>\n",
       "      <td>0.049108</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.016683</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.253676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>1446</td>\n",
       "      <td>7803</td>\n",
       "      <td>5151</td>\n",
       "      <td>935</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072127</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>0.217009</td>\n",
       "      <td>0.144403</td>\n",
       "      <td>0.892028</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>243</td>\n",
       "      <td>4325</td>\n",
       "      <td>1109</td>\n",
       "      <td>1903</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324770</td>\n",
       "      <td>0.384992</td>\n",
       "      <td>0.330680</td>\n",
       "      <td>0.072864</td>\n",
       "      <td>0.930373</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.136029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>419</td>\n",
       "      <td>743</td>\n",
       "      <td>7750</td>\n",
       "      <td>183</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131070</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.244936</td>\n",
       "      <td>0.158088</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.220588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1863</td>\n",
       "      <td>22693</td>\n",
       "      <td>5625</td>\n",
       "      <td>965</td>\n",
       "      <td>9</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.252794</td>\n",
       "      <td>0.080405</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>0.021806</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.113971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  var1  var2  var3   var4  var5  var6  var7  var8  var9  ...     var59  \\\n",
       "0   0     5   126  1353  28956   743  1289    27  -999     1  ...  0.201839   \n",
       "1   2     6   126  1446   7803  5151   935    35  -999     3  ...  0.072127   \n",
       "2   4     5    44   243   4325  1109  1903    33    24     1  ...  0.324770   \n",
       "3   7     4    53   419    743  7750   183    35  -999     3  ...  0.131070   \n",
       "4  15     4   126  1863  22693  5625   965     9  -999     3  ...  0.225166   \n",
       "\n",
       "        var60     var61     var62     var63     var64  var65  var66     var67  \\\n",
       "0    0.353965  0.166641  0.049108  0.986882  0.016683 -999.0 -999.0  0.176471   \n",
       "1    0.074555  0.217009  0.144403  0.892028  0.038323 -999.0 -999.0  0.147059   \n",
       "2    0.384992  0.330680  0.072864  0.930373  0.021052 -999.0 -999.0  0.294118   \n",
       "3 -999.000000  0.244936  0.158088  0.986882  0.022649 -999.0 -999.0  0.294118   \n",
       "4    0.059940  0.252794  0.080405  0.944501  0.021806 -999.0 -999.0  0.352941   \n",
       "\n",
       "      var68  \n",
       "0  0.253676  \n",
       "1  0.099265  \n",
       "2  0.136029  \n",
       "3  0.220588  \n",
       "4  0.113971  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data/test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   0          1\n",
       "1   2          1\n",
       "2   4          1\n",
       "3   7          0\n",
       "4  15          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv(\"../data/submission_sample.csv\")\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variavel cod</th>\n",
       "      <th>Variavel tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>var1</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>var2</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>var3</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var4</td>\n",
       "      <td>Qualitativo nominal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variavel cod        Variavel tipo\n",
       "0           id  Qualitativo nominal\n",
       "1         var1  Qualitativo nominal\n",
       "2         var2  Qualitativo nominal\n",
       "3         var3  Qualitativo nominal\n",
       "4         var4  Qualitativo nominal"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.read_csv(\"../data/metadata.csv\")\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qualitativo nominal      36\n",
       "Quantitativo discreto    18\n",
       "Quantitativo continua    12\n",
       "Qualitativo ordinal       4\n",
       "Name: Variavel tipo, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta[\"Variavel tipo\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vars type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **VariÃ¡vel qualitativa nominal** = valores que expressam atributos, sem\n",
    "nenhum tipo de ordem. Ex: cor dos olhos, sexo, estado civil, presenÃ§a ou\n",
    "ausÃªncia...\n",
    "\n",
    "\n",
    "- **VariÃ¡vel qualitativa ordinal** = valores que expressam atributos, porÃ©m com\n",
    "algum tipo de ordem, ou grau. Ex: grau de escolaridade (1Âº grau, 2Âº grau, 3Âº\n",
    "grau, pÃ³s-graduaÃ§Ã£o...); resposta de um paciente (nenhuma melhora, alguma\n",
    "melhora, muita melhora); classe social (alta, mÃ©dia, baixa)...\n",
    "\n",
    "\n",
    "- **VariÃ¡vel quantitativa discreta** = valores observados somente em pontos\n",
    "isolados ao longo de uma escala de valores (contagem). Valores positivos\n",
    "inteiros (incluindo o zero). Ex: No de filhos; No de faltas; alunos com notas abaixo de 5,0.\n",
    "\n",
    "\n",
    "- **VariÃ¡vel quantitativa contÃ­nua** = valores em qualquer ponto fracionÃ¡rio ao\n",
    "longo de um intervalo especificado de valores (mediÃ§Ã£o). Ex: temperatura do\n",
    "corpo; altura (em metros); Ã­ndice do PIB..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variavel tipo\n",
       "Qualitativo nominal      [var1, var2, var3, var4, var5, var6, var7, var...\n",
       "Qualitativo ordinal                           [var26, var32, var42, var43]\n",
       "Quantitativo continua    [var55, var56, var57, var58, var59, var60, var...\n",
       "Quantitativo discreto    [var24, var25, var27, var40, var44, var45, var...\n",
       "Name: Variavel cod, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_type = df_meta.drop(0).groupby(\"Variavel tipo\")[\"Variavel cod\"].apply(list)\n",
    "cols_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many approaches to feature engineering, which could be also used on anonymized data:\n",
    "\n",
    "- transformation of continuous variables: log, power, normalization;\n",
    "- aggregations: `df.groupby(['cat_column']).agg({'continuous_column': ['min', 'max', 'mean', 'std'])\n",
    "- interactions of continuous variables: addition, subtraction, multiplications, division And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df_train.drop([\"id\", TARGET], axis=1).apply(np.log)\n",
    "# df_temp.columns = [f\"{col}_log\" for col in df_temp.columns]\n",
    "# df_train = pd.concat([df_train, df_temp], axis=1)\n",
    "\n",
    "# df_temp = df_train.drop([\"id\", TARGET], axis=1).apply(lambda x: np.power(x, 2))\n",
    "# df_temp.columns = [f\"{col}_pow2\" for col in df_temp.columns]\n",
    "# df_train = pd.concat([df_train, df_temp], axis=1)\n",
    "\n",
    "# print(df_train.shape)\n",
    "# df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df_test.drop(\"id\", axis=1).apply(np.log)\n",
    "# df_temp.columns = [f\"{col}_log\" for col in df_temp.columns]\n",
    "# df_test = pd.concat([df_test, df_temp], axis=1)\n",
    "\n",
    "# df_temp = df_test.drop(\"id\", axis=1).apply(lambda x: np.power(x, 2))\n",
    "# df_temp.columns = [f\"{col}_pow2\" for col in df_temp.columns]\n",
    "# df_test = pd.concat([df_test, df_temp], axis=1)\n",
    "\n",
    "# print(df_test.shape)\n",
    "# df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_abs_scl = MaxAbsScaler()\n",
    "# min_max_scl = MinMaxScaler()\n",
    "# std_scl = StandardScaler()\n",
    "# robust_scaler = RobustScaler()\n",
    "\n",
    "# scalers = [\n",
    "#     (max_abs_scl, \"max_abs\"),\n",
    "#     (min_max_scl, \"min_max\"),\n",
    "#     (std_scl, \"std_scl\"),\n",
    "#     (robust_scaler, \"rob_scl\")\n",
    "# ]\n",
    "# cols_to_drop = [ft for ft in df_train.columns if \"_\" in ft]\n",
    "# # cols_to_drop.append(\"y\")\n",
    "# # cols_to_drop.append(\"id\")\n",
    "\n",
    "# for scl in scalers:\n",
    "#     df_train_temp = df_train.drop(cols_to_drop + [TARGET], axis=1)\n",
    "#     df_test_temp = df_test.drop(cols_to_drop, axis=1)\n",
    "#     scl[0].fit(pd.concat([df_train_temp, df_test_temp], axis=0))\n",
    "    \n",
    "#     new_cols = [f\"{col}_{scl[1]}\" for col in df_train_temp.columns]\n",
    "#     df_train[new_cols] = scl[0].transform(df_train_temp)\n",
    "    \n",
    "#     new_cols = [f\"{col}_{scl[1]}\" for col in df_test_temp.columns]\n",
    "#     df_test[new_cols] = scl[0].transform(df_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14123, 70), (21183, 69))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'has one feat' features from kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/89003\n",
    "https://www.kaggle.com/fl2ooo/create-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variavel tipo\n",
       "Qualitativo nominal      [var1, var2, var3, var4, var5, var6, var7, var...\n",
       "Qualitativo ordinal                           [var26, var32, var42, var43]\n",
       "Quantitativo continua    [var55, var56, var57, var58, var59, var60, var...\n",
       "Quantitativo discreto    [var24, var25, var27, var40, var44, var45, var...\n",
       "Name: Variavel cod, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variavel tipo\n",
       "Qualitativo nominal      35\n",
       "Qualitativo ordinal       4\n",
       "Quantitativo continua    12\n",
       "Quantitativo discreto    18\n",
       "Name: Variavel cod, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_type.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:00<00:00, 219.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "orig = df_test.columns# + cols_type[\"Qualitativo ordinal\"]\n",
    "# orig = df_test.columns\n",
    "has_one = [f'{col}_has_one' for col in orig]\n",
    "has_zero = [f'{col}_has_zero' for col in orig]\n",
    "not_u = [f'{orig}_not_unique' for col in orig]\n",
    "\n",
    "for f in tqdm(orig):\n",
    "    unique_v = df_test[f].value_counts()\n",
    "    unique_v = unique_v.index[unique_v == 1]\n",
    "    df_test[f + '_u'] = df_test[f].isin(unique_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21183\n"
     ]
    }
   ],
   "source": [
    "df_test['has_unique'] = df_test[[f + '_u' for f in orig]].any(axis=1)\n",
    "print(df_test['has_unique'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35306, 70)\n"
     ]
    }
   ],
   "source": [
    "real_samples = df_test.loc[df_test['has_unique'], orig]\n",
    "ref = pd.concat([df_train, real_samples], axis=0)\n",
    "print(ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 25.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(orig):\n",
    "    df_train[f + '_has_one'] = 0\n",
    "    df_train[f + '_has_zero'] = 0\n",
    "    f_1 = df_train.loc[df_train[TARGET] == 1, f].value_counts()\n",
    "    \n",
    "    f_1_1 = set(f_1.index[f_1 > 1])\n",
    "    f_0_1 = set(f_1.index[f_1 > 0])\n",
    "\n",
    "    f_0 = df_train.loc[df_train[TARGET] == 0, f].value_counts()\n",
    "    f_0_0 = set(f_0.index[f_0 > 1])\n",
    "    f_1_0 = set(f_0.index[f_0 > 0])\n",
    "    \n",
    "    df_train.loc[df_train[TARGET] == 1, f + '_has_one'] = df_train.loc[df_train[TARGET] == 1, f].isin(f_1_1).astype(int)\n",
    "    df_train.loc[df_train[TARGET] == 0, f + '_has_one'] = df_train.loc[df_train[TARGET] == 0, f].isin(f_0_1).astype(int)\n",
    "\n",
    "    df_train.loc[df_train[TARGET] == 1, f + '_has_zero'] = df_train.loc[df_train[TARGET] == 1, f].isin(f_1_0).astype(int)\n",
    "    df_train.loc[df_train[TARGET] == 0, f + '_has_zero'] = df_train.loc[df_train[TARGET] == 0, f].isin(f_0_0).astype(int)\n",
    "\n",
    "df_train.loc[:, has_one] = 2*df_train.loc[:, has_one].values + df_train.loc[:, has_zero].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:01<00:00, 41.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(orig):\n",
    "    df_test[f + '_has_one'] = 0\n",
    "    df_test[f + '_has_zero'] = 0\n",
    "    f_1 = df_train.loc[df_train[TARGET] == 1, f].unique()\n",
    "    f_0 = df_train.loc[df_train[TARGET] == 0, f].unique()\n",
    "    df_test.loc[:, f + '_has_one'] = df_test[f].isin(f_1).astype(int)\n",
    "    df_test.loc[:, f + '_has_zero'] = df_test[f].isin(f_0).astype(int)\n",
    "    \n",
    "df_test.loc[:, has_one] = 2*df_test.loc[:, has_one].values + df_test.loc[:, has_zero].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:01<00:00, 46.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(orig):\n",
    "    v = ref[f].value_counts()\n",
    "    \n",
    "    non_unique_v = v.index[v != 1]\n",
    "    \n",
    "    m_trd = df_train[f].isin(non_unique_v)\n",
    "    df_train[f + '_not_unique'] = m_trd  * df_train[f] + (~m_trd) * df_train[f].mean()\n",
    "    \n",
    "    m_df_test = df_test[f].isin(non_unique_v)\n",
    "    df_test[f + '_not_unique'] = m_df_test  * df_test[f] + (~m_df_test) * df_train[f].mean()\n",
    "    \n",
    "    df_train.loc[~m_trd, f + '_has_one'] = 4\n",
    "    df_test.loc[~m_df_test, f + '_has_one'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = cols_type['Qualitativo nominal']\n",
    "# cols.extend(cols_type['Qualitativo ordinal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14123, 277), (21183, 346))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[~df_train.columns.isin(df_test.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_u', 'var1_u', 'var2_u', 'var3_u', 'var4_u', 'var5_u', 'var6_u',\n",
       "       'var7_u', 'var8_u', 'var9_u', 'var10_u', 'var11_u', 'var12_u',\n",
       "       'var13_u', 'var14_u', 'var15_u', 'var16_u', 'var17_u', 'var18_u',\n",
       "       'var19_u', 'var20_u', 'var21_u', 'var22_u', 'var23_u', 'var24_u',\n",
       "       'var25_u', 'var26_u', 'var27_u', 'var28_u', 'var29_u', 'var30_u',\n",
       "       'var31_u', 'var32_u', 'var33_u', 'var34_u', 'var35_u', 'var36_u',\n",
       "       'var37_u', 'var38_u', 'var39_u', 'var40_u', 'var41_u', 'var42_u',\n",
       "       'var43_u', 'var44_u', 'var45_u', 'var46_u', 'var47_u', 'var48_u',\n",
       "       'var49_u', 'var50_u', 'var51_u', 'var52_u', 'var53_u', 'var54_u',\n",
       "       'var55_u', 'var56_u', 'var57_u', 'var58_u', 'var59_u', 'var60_u',\n",
       "       'var61_u', 'var62_u', 'var63_u', 'var64_u', 'var65_u', 'var66_u',\n",
       "       'var67_u', 'var68_u', 'has_unique'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns[~df_test.columns.isin(df_train.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's auc: 0.892549\tvalid_0's binary_logloss: 0.311497\n",
      "[1000]\tvalid_0's auc: 0.894612\tvalid_0's binary_logloss: 0.307956\n",
      "Early stopping, best iteration is:\n",
      "[739]\tvalid_0's auc: 0.895568\tvalid_0's binary_logloss: 0.307517\n",
      "Fold 1, AUC: 0.8955677441941885\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's auc: 0.886779\tvalid_0's binary_logloss: 0.30797\n",
      "[1000]\tvalid_0's auc: 0.889032\tvalid_0's binary_logloss: 0.304937\n",
      "[1500]\tvalid_0's auc: 0.889794\tvalid_0's binary_logloss: 0.306237\n",
      "Early stopping, best iteration is:\n",
      "[1053]\tvalid_0's auc: 0.889493\tvalid_0's binary_logloss: 0.304813\n",
      "Fold 2, AUC: 0.8894931341657915\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's auc: 0.894636\tvalid_0's binary_logloss: 0.302878\n",
      "[1000]\tvalid_0's auc: 0.897626\tvalid_0's binary_logloss: 0.297806\n",
      "[1500]\tvalid_0's auc: 0.897817\tvalid_0's binary_logloss: 0.298879\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's auc: 0.898327\tvalid_0's binary_logloss: 0.297561\n",
      "Fold 3, AUC: 0.8983265258489905\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's auc: 0.891008\tvalid_0's binary_logloss: 0.30993\n",
      "[1000]\tvalid_0's auc: 0.892177\tvalid_0's binary_logloss: 0.308349\n",
      "Early stopping, best iteration is:\n",
      "[869]\tvalid_0's auc: 0.892484\tvalid_0's binary_logloss: 0.307423\n",
      "Fold 4, AUC: 0.8924835380376408\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's auc: 0.884515\tvalid_0's binary_logloss: 0.312722\n",
      "[1000]\tvalid_0's auc: 0.887575\tvalid_0's binary_logloss: 0.309913\n",
      "[1500]\tvalid_0's auc: 0.888505\tvalid_0's binary_logloss: 0.311879\n",
      "Early stopping, best iteration is:\n",
      "[1150]\tvalid_0's auc: 0.888467\tvalid_0's binary_logloss: 0.30954\n",
      "Fold 5, AUC: 0.8884672862279923\n",
      "CV AUC: 0.8928681012386374\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "features_to_drop = [TARGET]\n",
    "features = [ft for ft in df_train.columns if ft not in features_to_drop]\n",
    "\n",
    "importances = df_train[features].columns.to_frame()\n",
    "train_preds = df_train[TARGET].to_frame()\n",
    "train_preds[\"preds\"] = 0\n",
    "\n",
    "df_sub[\"predicted\"] = 0\n",
    "df_sub[TARGET] = 0\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "for fold, (train_index, valid_index) in enumerate(kfold.split(df_train, df_train[TARGET])):\n",
    "    x_train, x_valid = df_train.loc[train_index][features], df_train.loc[valid_index][features]\n",
    "    y_train, y_valid = df_train.loc[train_index][TARGET], df_train.loc[valid_index][TARGET]\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=5000,\n",
    "        random_state=SEED,\n",
    "        boosting=\"gbdt\",\n",
    "        objective=\"binary\",\n",
    "        subsample=0.8,\n",
    "        subsample_freq=10,\n",
    "        colsample_bytree=0.8,\n",
    "        max_depth=-1\n",
    "    )\n",
    "#     clf = lgb.LGBMClassifier(\n",
    "#         bagging_freq=5,\n",
    "#         bagging_fraction=1.0,\n",
    "#         n_estimators=5000,\n",
    "#         boost_from_average=False,\n",
    "#         boost='gbdt',\n",
    "#         feature_fraction= 1.0,\n",
    "#         learning_rate= 0.005,\n",
    "#         max_depth= -1,\n",
    "#         metric='binary_logloss',\n",
    "#         min_data_in_leaf= 30,\n",
    "#         min_sum_hessian_in_leaf= 10.0,\n",
    "#         num_leaves=64,\n",
    "#         num_threads= -1,\n",
    "#         tree_learner= 'serial',\n",
    "#         objective='binary'\n",
    "#     )\n",
    "    \n",
    "    clf.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "#         categorical_feature=cols,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        eval_metric=\"auc\",\n",
    "        early_stopping_rounds=500,\n",
    "        verbose=500\n",
    "    )\n",
    "    \n",
    "    y_pred = clf.predict_proba(x_valid, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    y_pred = (pd.Series(y_pred).rank()/len(x_valid)).values\n",
    "    train_preds.loc[valid_index, \"preds\"] = y_pred\n",
    "    \n",
    "    test_preds = clf.predict_proba(df_test[features], num_iteration=clf.best_iteration_)[:, 1]\n",
    "    test_preds = (pd.Series(test_preds).rank()/len(test_preds)).values\n",
    "    df_sub[TARGET] += test_preds/FOLDS\n",
    "    \n",
    "    importances[fold] = clf.feature_importances_    \n",
    "    \n",
    "    print(f\"Fold {fold+1}, AUC: {roc_auc_score(y_valid, y_pred)}\")\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"CV AUC: {roc_auc_score(train_preds[TARGET], train_preds['preds'])}\")\n",
    "      \n",
    "# fold 1 AUC 0.8970132649\n",
    "# fold 2 AUC 0.8917944529\n",
    "# fold 3 AUC 0.9014680826\n",
    "# fold 4 AUC 0.8959658463\n",
    "# fold 5 AUC 0.8873916157\n",
    "# OOF AUC 0.8947271932\n",
    "# OOF F1 0.6857142857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 64/1000 [00:01<00:24, 37.59it/s]"
     ]
    }
   ],
   "source": [
    "f1, precision, recall = [], [], []\n",
    "max_f1_threshold = -1\n",
    "max_f1 = -1\n",
    "for i in tqdm(range(1000)):\n",
    "    _i = i / 1000.0\n",
    "    \n",
    "    y_pred = np.where(train_preds[\"preds\"] > _i, 1, 0)\n",
    "    \n",
    "    _precision = precision_score(train_preds[TARGET], y_pred)\n",
    "    if _precision == 1.0:\n",
    "        break\n",
    "    _f1 = f1_score(train_preds[TARGET], y_pred)\n",
    "    if _f1 > max_f1:\n",
    "        max_f1 = _f1\n",
    "        max_f1_threshold = _i\n",
    "    \n",
    "    f1.append(_f1)\n",
    "    precision.append(_precision)\n",
    "    recall.append(recall_score(train_preds[TARGET], y_pred))\n",
    "    \n",
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(range(len(f1)), f1, label=\"f1\")\n",
    "plt.plot(range(len(f1)), precision, label=\"precision\")\n",
    "plt.plot(range(len(f1)), recall, label=\"recall\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"max_f1 [{max_f1_threshold}]: {max_f1}\")\n",
    "# max_f1 [0.776]: 0.6822942643391521"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importances_sorted = importances.mean(axis=1).sort_values(ascending=False).head(100)\n",
    "plt.figure(figsize=(10,15))\n",
    "sns.barplot(y=importances_sorted.index, x=importances_sorted, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip and save sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"VERSION ::: {VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[TARGET].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"predicted\"] = np.where(df_sub[TARGET] > max_f1_threshold, 1, 0)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[[\"predicted\", \"y\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.columns = [\"predicted\", \"y\"]\n",
    "train_preds[\"predicted\"] = np.where(train_preds[\"y\"] > max_f1_threshold, 1, 0)\n",
    "train_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds[\"id\"] = df_train[\"id\"]\n",
    "train_preds = train_preds[[\"id\", \"predicted\", \"y\"]]\n",
    "train_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.to_csv(f\"../output/mario/train_preds_{VERSION}.csv\", index=False)\n",
    "df_sub.to_csv(f\"../output/mario/test_preds_{VERSION}.csv\", index=False)\n",
    "df_sub.drop(\"y\", axis=1).to_csv(f\"../output/mario/sub_{VERSION}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=df_train[TARGET], y_pred=np.where(train_preds[TARGET] > max_f1_threshold, 1, 0), labels=[0, 1])\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt=\"g\", ax=ax);  #annot=True to annotate cells, ftm=\"g\" to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel(\"Predicted labels\");\n",
    "ax.set_ylabel(\"True labels\"); \n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
